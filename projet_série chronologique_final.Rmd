---
title: "S√©rie chronologique : Churn Bancaire"
author: "Akbar Fahardine / Yacouba CISSE"
date: "`r Sys.Date()`"
output:
  html_document:
    theme: flatly  # Th√®me Bootstrap pour un design moderne
    toc: true  # Table des mati√®res
    toc_depth: 2  # Profondeur de la TOC
    toc_float: true  # TOC flottante √† gauche
    number_sections: true  # Num√©rotation des sections
---

<!-- Ajout de l'image apr√®s le titre -->

<center><img src="https://www.actuia.com/wp-content/uploads/2023/05/Influxdata-InfluxDB-3.0-base-donnees-nouvelle-generation-analyse-series-chronologiques-1200x600.png" alt="Analyse de s√©ries chronologiques" width="80%"/></center>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

```{r, echo=FALSE, results='asis'}
cat("
<style>
/* Couleur de fond et texte global */
body {
  background-color: #f4f4f4; /* Fond gris clair */
  color: #333; /* Texte gris fonc√© */
  font-family: 'Arial', sans-serif;
}

/* Style des titres */
h1 {
  color: #007acc; /* Bleu vif */
  text-transform: uppercase;
  font-weight: bold;
  text-align: center;
  border-bottom: 3px solid #007acc;
  padding-bottom: 10px;
}
h2 {
  color: #005580; /* Bleu fonc√© */
  font-weight: bold;
  margin-top: 30px;
}
h3 {
  color: #004466; /* Bleu fonc√© plus sombre */
  font-weight: bold;
}

/* Style des tableaux */
table {
  width: 100%;
  border-collapse: collapse;
  background-color: #fff;
  box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
}
th {
  background-color: #007acc;
  color: white;
  padding: 10px;
  text-transform: uppercase;
}
td {
  border: 1px solid #ccc;
  padding: 8px;
  text-align: left;
}
</style>
")
```

# Introduction

Ce projet se base sur l'analyse des transactions bancaires issues d'un jeu de donn√©es public disponible sur Kaggle, collect√© en Inde. Les informations fournies incluent des d√©tails socio-d√©mographiques des clients, ainsi que des indicateurs d'activit√©s de comptes et des donn√©es de transactions, exprim√©es en roupies indiennes (INR). Ce contexte permet d'explorer les comportements des clients dans le cadre du secteur bancaire indien, offrant ainsi une perspective unique sur les dynamiques financi√®res de cette r√©gion.

Notre jeu de donn√©e est issu de Kaggle : [la d√©sertion bancaire](https://www.kaggle.com/code/mohamedchahed/pr-diction-de-la-d-sertion-bancaire) 

**Probl√©matique**: **Comment pr√©dire les flux de tr√©sorerie futurs en analysant les s√©ries temporelles des d√©p√¥ts et retraits sur les comptes bancaires ?**

## Tableau explicatif de nos Variables

| Nom de la Variable  | Type        | Label                     |
|---------------------|-------------|---------------------------|
| Account No          | Identifiant | Num√©ro de compte          |
| DATE                | Date        | Date de la transaction    |
| TRANSACTION DETAILS | Texte       | D√©tails de la transaction |
| CHQ.NO.             | Num√©rique   | Num√©ro de ch√®que          |
| VALUE DATE          | Date        | Date de valeur            |
| WITHDRAWAL AMT      | Num√©rique   | Montant de retrait        |
| DEPOSIT AMT         | Num√©rique   | Montant de d√©p√¥t          |
| BALANCE AMT         | Num√©rique   | Montant du solde          |

-   Dans le tableau fourni, il y a un total de 5 variables num√©riques et 3 variables de type caract√®re.

-   Les variables num√©riques comprennent CHQ.NO., WITHDRAWAL AMT, DEPOSIT AMT et BALANCE AMT, qui sont des montants ou des identifiants quantitatifs.

-   Les variables de type caract√®re incluent Account No, TRANSACTION DETAILS, et DATE, qui contiennent des informations descriptives ou identifiantes. Ce m√©lange de types de variables permet une analyse compl√®te des transactions financi√®res.

```{r}
# Charger le package n?cessaire
library(openxlsx)

# Charger le package n?cessaire
library(openxlsx)

# Lire le fichier Excel
#df <- read.xlsx("C:/Users/Scolaire/Documents/Prevition temporelle/data.xlsx", detectDates = TRUE)
df <- read.xlsx("~/Documents/Master 2/SeÃÅrie temporelle ou chronologique/Copie de bank1.xlsx")
#df

# Afficher la structure du dataframe pour v?rifier les types
#str(df)


```

```{r}
# Remplacer les valeurs manquantes par 0 dans les colonnes DEPOSIT.AMT et WITHDRAWAL.AMT
df$DEPOSIT.AMT[is.na(df$DEPOSIT.AMT)] <- 0
df$WITHDRAWAL.AMT[is.na(df$WITHDRAWAL.AMT)] <- 0
# Cr√©er la colonne 'flux' en combinant les d√©p√¥ts et les retraits
df$flux <- ifelse(df$DEPOSIT.AMT > 0, df$DEPOSIT.AMT, 
                  ifelse(df$WITHDRAWAL.AMT > 0, -df$WITHDRAWAL.AMT, NA))
# Cr√©er la colonne 'flux' en ajoutant les d√©p√¥ts et les retraits (n√©gatifs)
df$flux <- df$DEPOSIT.AMT - df$WITHDRAWAL.AMT



# V√©rifier le r√©sultat
head(df)


```

# Visualisation des s√©ries

## Evolution de la variable cible en fonction du temps

```{r}
# Charger les biblioth√®ques n√©cessaires
library(ggplot2)
library(dplyr)  # Pour le regroupement de donn√©es
library(fpp2)   # Pour autoplot

# S'assurer que la colonne 'DATE' est au format Date
df$DATE <- as.Date(df$DATE, origin = "1900-01-01")

# Remplacer les valeurs manquantes par 0 dans les colonnes DEPOSIT.AMT et WITHDRAWAL.AMT
df$DEPOSIT.AMT[is.na(df$DEPOSIT.AMT)] <- 0
df$WITHDRAWAL.AMT[is.na(df$WITHDRAWAL.AMT)] <- 0

# Calculer le flux pour chaque ligne
df$flux <- df$DEPOSIT.AMT - df$WITHDRAWAL.AMT

# Compter le flux total par jour
flux_per_day <- df %>%
  group_by(DATE) %>%
  summarise(flux = sum(flux))

# Identifier la date de d√©but et la date de fin
start_date <- min(flux_per_day$DATE)
end_date <- max(flux_per_day$DATE)

# Cr√©er la s√©rie temporelle √† partir des flux par jour
df_ts_jour <- ts(flux_per_day$flux, start = c(as.numeric(format(start_date, "%Y")), as.numeric(format(start_date, "%m"))), frequency = 365)

# Visualiser la s√©rie temporelle avec autoplot
autoplot(df_ts_jour) +
  ggtitle("√âvolution du flux par jour") +
  ylab("Flux") +
  xlab("Date") +
  theme_minimal()


```

Ce graphique montre l'√©volution du flux de transactions bancaires jour apr√®s jour, de 2015 √† 2018. Les variations dans les valeurs indiquent que le flux quotidien a des fluctuations importantes, avec des pics notables en 2016 et en 2017, o√π les flux atteignent des niveaux tr√®s √©lev√©s et tr√®s bas..

```{r}
# Extraire l'ann√©e de chaque date
flux_per_day <- flux_per_day %>%
  mutate(annee = format(DATE, "%Y"))

# Trouver les dates avec les pics max et min chaque ann√©e
max_min_pics <- flux_per_day %>%
  group_by(annee) %>%
  summarise(date_max_flux = DATE[which.max(flux)],
            max_flux = max(flux),
            date_min_flux = DATE[which.min(flux)],
            min_flux = min(flux))

# Afficher les r√©sultats
print(max_min_pics)


```

Les dates associ√©es aux pics maximaux et minimaux dans les flux financiers observ√©s chaque ann√©e en Inde peuvent refl√©ter des √©v√©nements √©conomiques sp√©cifiques ou des tendances saisonni√®res influen√ßant les d√©p√¥ts et les retraits. En 2015, le pic maximal du 25 juillet pourrait co√Øncider avec la saison des soldes ou des p√©riodes de hausse d'activit√© √©conomique, tandis que le pic minimal du 20 juin correspond probablement √† un ralentissement d√ª √† la mousson, un facteur souvent d√©favorable aux affaires. En 2016, le pic maximal de f√©vrier peut √™tre li√© aux ajustements financiers de fin d‚Äôann√©e fiscale, tandis que la chute du 8 mars pourrait refl√©ter des d√©penses massives avant cette cl√¥ture. En 2017, le pic d‚Äôavril semble √™tre en lien avec le d√©but de la nouvelle ann√©e fiscale, tandis que le flux n√©gatif de mai pourrait s‚Äôexpliquer par les paiements d‚Äôimp√¥ts ou les ajustements post-fiscaux. En 2018, les m√™mes ph√©nom√®nes se r√©p√®tent, avec un pic de flux en f√©vrier et une baisse en juin, saison des moussons. Enfin, en 2019, le flux maximal de d√©but janvier pourrait s'expliquer par des r√©ajustements financiers de d√©but d‚Äôann√©e, tandis que la baisse en fin de mois pourrait √™tre due √† des paiements fiscaux. Ces variations annuelles montrent un lien √©troit entre les cycles financiers, les √©v√©nements √©conomiques et les saisons en Inde

## Visualisation par mois

```{r}
# Charger les biblioth√®ques n√©cessaires
library(ggplot2)
library(dplyr)
library(lubridate)

# Supposons que df soit votre dataframe et que 'DEPOSIT.AMT' et 'WITHDRAWAL.AMT' soient vos colonnes de montants
# Convertir la colonne DATE en format Date
df$DATE <- as.Date(df$DATE)



# Cr√©er une nouvelle colonne 'Mois' pour extraire le mois
df <- df %>%
  mutate(Mois = floor_date(DATE, "month"))  # Arrondir au d√©but du mois

# Agr√©ger les donn√©es par mois pour obtenir le flux total
df_monthly_flux <- df %>%
  group_by(Mois) %>%
  summarise(Flux_Total = sum(flux, na.rm = TRUE))  # Somme des flux par mois

# Cr√©er un graphique du flux total par mois en utilisant ggmonthplot
ggmonthplot(ts(df_monthly_flux$Flux_Total, frequency = 12, start = c(year(min(df_monthly_flux$Mois)), month(min(df_monthly_flux$Mois))))) +
  ggtitle("Flux Total par Mois") +
  ylab("Flux Total") +
  xlab("Mois")

```

Ici, le flux total est pr√©sent√© mensuellement, avec des moyennes marqu√©es par des lignes bleues. On observe des pics en termes de flux, principalement autour des mois de f√©vrier, mars, et avril, avec des fluctuations importantes √† travers l'ann√©e.

## Visualisation saisoni√®re

```{r}
# Installer le package ggfortify si ce n'est pas encore fait
# install.packages("ggfortify")  # D√©commenter cette ligne si n√©cessaire

# Charger les biblioth√®ques n√©cessaires
library(forecast)
library(ggplot2)
library(dplyr)
library(lubridate)
library(ggfortify)  # Pour ggseasonplot
library(ggpubr)     # Pour ggarrange

# Supposons que df soit votre dataframe et que 'DEPOSIT.AMT' et 'WITHDRAWAL.AMT' soient vos colonnes de montants
# Convertir la colonne DATE en format Date
df$DATE <- as.Date(df$DATE)


# Cr√©er une nouvelle colonne 'Mois' pour extraire le mois
df <- df %>%
  mutate(Mois = floor_date(DATE, "month"))  # Arrondir au d√©but du mois

# Agr√©ger les donn√©es par mois pour obtenir le flux total
df_monthly_flux <- df %>%
  group_by(Mois) %>%
  summarise(Flux_Total = sum(flux, na.rm = TRUE))  # Somme des flux par mois

# Cr√©er la s√©rie temporelle √† partir des donn√©es mensuelles
df_ts_mois <- ts(df_monthly_flux$Flux_Total, frequency = 12, start = c(year(min(df_monthly_flux$Mois)), month(min(df_monthly_flux$Mois))))

# Cr√©er le premier graphique saisonnier pour le flux
p1 <- ggseasonplot(df_ts_mois) +
  ggtitle("Graphique saisonnier: Flux Total") +
  ylab("Flux Total") +
  xlab("Mois")

# Cr√©er le deuxi√®me graphique saisonnier continu pour le flux
#p2 <- ggseasonplot(df_ts, continuous = TRUE) +
 # ggtitle("Graphique saisonnier continu: Flux Total") +
  #ylab("Flux Total") +
  #xlab("Mois")

# Afficher les deux graphiques c√¥te √† c√¥te
#ggarrange(p1, p2, ncol = 2, nrow = 1)

ggarrange(p1, ncol = 1, nrow = 1)

```

Ce graphique pr√©sente une vue saisonni√®re du flux total par mois pour les ann√©es de 2015 √† 2019. Chaque couleur repr√©sente une ann√©e. Il montre une tendance annuelle des transactions, avec des pics en avril et juillet, suivis d'une baisse marqu√©e en juin et d√©cembre.

```{r}
# Supposons que df soit votre dataframe et que 'DEPOSIT.AMT' et 'WITHDRAWAL.AMT' soient vos colonnes de montants
# Convertir la colonne DATE en format Date
df$DATE <- as.Date(df$DATE)


# Cr√©er une nouvelle colonne 'Mois' pour extraire le mois
df <- df %>%
  mutate(Mois = floor_date(DATE, "month"))  # Arrondir au d√©but du mois

# Agr√©ger les donn√©es par mois pour obtenir le flux total
df_monthly_flux <- df %>%
  group_by(Mois) %>%
  summarise(Flux_Total = sum(flux, na.rm = TRUE))  # Somme des flux par mois

# Cr√©er la s√©rie temporelle √† partir des donn√©es mensuelles
df_ts_mois <- ts(df_monthly_flux$Flux_Total, frequency = 12, start = c(year(min(df_monthly_flux$Mois)), month(min(df_monthly_flux$Mois))))

# Cr√©er un graphique saisonnier polaire pour le flux
saison_polar = ggseasonplot(df_ts_mois, polar = TRUE) +
  ylab("Flux Total") +
  ggtitle("Graphique saisonnier polaire: Flux Total par Mois")

ggarrange(saison_polar, ncol = 1, nrow = 1)
```

# Autocor√©lation : Analyse de corr√©lation dans le temps

## Formulation math√©matique : Notions de ACF (Autocorelation Function ) et PACF (Partial Autocorelation Function )

La formule de la corr√©lation œÅ(h) :

$$ \rho(h) = \text{cor}(Y_t, Y_{t-h}) = \text{cor}(Y_t, Y_{t+h}) \quad     \text{pour tout} \; h \geq 0 \\
 \text{quelque soit la date}, \; t $$

La corr√©lation $\rho(h)$ ne d√©pend pas du temps.

La formule pour $r(h)$ :

$$
r(h) = \text{cor}\left(\text{R√©sidu}\left(\text{lm}(Y_t \sim Y_{t+1}, ..., Y_{t+h-1})\right), \text{R√©sidu}\left(\text{lm}(Y_{t+h} \sim Y_{t+1}, ..., Y_{t+h-1})\right)\right) \\
\text{pour tout} \; h \geq 0 \\
\text{quelque soit la date}, \; t
$$t

\##

```{r}
gglagplot(df_ts_mois,do.lines = FALSE)
```

```{r}
library(astsa)
lag1.plot(df_ts_mois,max.lag=6)
```

## Graphique ACF et PACF

```{r}
par(mfrow=c(1,3))
  plot(df_ts_jour)
  Acf(df_ts_jour,lag=10)# Changer √©ventuellement le lag
  Pacf(df_ts_jour,lag=10)
```

## Utilit√© de l‚ÄôACF et PACF : stationnarit√© et p√©riodicit√©

L‚ÄôACF et PACF sont d√©finis sous hypoth√®se de stationnarit√© : Les corr√©lations œÅ(h) et \r(h) ne d√©pendent pas du temps.

Les graphiques de ACF et PACF permettent de d√©tecter des processus stationnaires : ARMA, ARIMA, SARMA, SARIMA,..(Voir partie al√©atoire) √âventuellement certaines p√©riodicit√©s

```{r}

ggarrange(autoplot(df_ts_jour),ggAcf(df_ts_jour,lag=100 ),ggPacf(df_ts_jour,lag=100 ),nrow=1 )
```

Dans notre cas notre serie semble stationnaire.

# Application des m√©thodes de r√©gression

Les m√©thodes de r√©gression (lin√©aire, polynomiale, GAM, B-spline) sont utilis√©es pour mod√©liser la tendance globale de la s√©rie temporelle et faire des pr√©dictions √† moyen/long terme.

## R√©gression Lin√©aire

La r√©gression lin√©aire simple mod√©lise la relation entre une variable d√©pendante Y et une seule variable ind√©pendante X . Elle suppose une relation lin√©aire entre ces deux variables.

$$
Y_t = \beta_0 + \beta_1 t + \epsilon_t
$$

-   $Y_t$ : valeur de la s√©rie chronologique √† l'instant $t$\
-   $t$ : le temps\
-   $\beta_0$ : l'ordonn√©e √† l'origine\
-   $\beta_1$ : le coefficient de pente\
-   $\epsilon_t$ : le terme d'erreur al√©atoire

```{r}
# Mod√®le lin√©aire
time <- time(df_ts_jour)  # D√©finir le temps en fonction de la s√©rie temporelle
fit_lin <- lm(df_ts_jour ~ time)  # Ajuster le mod√®le lin√©aire

# Calculer AIC et BIC
aic_fit_lin <- AIC(fit_lin)
bic_fit_lin <- BIC(fit_lin)

# Extraire les r√©sidus
residuals_lin <- residuals(fit_lin)

# Calculer RMSE
rmse_fit_lin <- sqrt(mean(residuals_lin^2, na.rm = TRUE))

# Calculer MAE
mae_fit_lin <- mean(abs(residuals_lin), na.rm = TRUE)

# Afficher les r√©sultats
cat("AIC du mod√®le lin√©aire :", aic_fit_lin, "\n")
cat("BIC du mod√®le lin√©aire :", bic_fit_lin, "\n")
cat("RMSE du mod√®le lin√©aire :", rmse_fit_lin, "\n")
cat("MAE du mod√®le lin√©aire :", mae_fit_lin, "\n")

# R√©sum√© du mod√®le
summary(fit_lin)
```

Les r√©sultats montrent que le mod√®le lin√©aire ne capture pas bien les variations de la s√©rie chronologique. Les coefficients ne sont pas significatifs, et le R-squared est tr√®s faible. En r√©sum√©, ce mod√®le n'explique pas bien les donn√©es observ√©es. Il serait pertinent d'explorer des mod√®les plus complexes ou de v√©rifier la qualit√© des donn√©es.

## R√©gression polynomial

La r√©gression polynomiale est utilis√©e pour mod√©liser une relation non lin√©aire entre la variable d√©pendante Y et une ou plusieurs variables ind√©pendantes X . Elle est une extension de la r√©gression lin√©aire avec des termes de puissances sup√©rieures.

$$
Y_t = \beta_0 + \beta_1 t + \beta_2 t^2 + \beta_3 t^3 + \ldots + \beta_k t^k + \epsilon_t
$$

-   $k$ : le degr√© du polyn√¥me\
-   $\beta_0, \beta_1, \ldots, \beta_k$ : coefficients des termes polynomiaux\
-   $\epsilon_t$ : le terme d'erreur

Le mod√®le polyn√¥mial de degr√© 3 semble capturer des tendances significatives dans les donn√©es, m√™me si le R-squared est relativement bas. Cela indique que, bien que le mod√®le soit significatif, il reste beaucoup de variabilit√© dans les donn√©es qui n'est pas expliqu√©e par ce mod√®le.

```{r}
# üìå Cr√©er une copie avant modification
df_ts_jour_original <- df_ts_jour  # Sauvegarde l'original
```

```{r}
# üìå Charger les biblioth√®ques n√©cessaires
library(ggplot2)
library(dplyr)
library(zoo)  # Pour interpolation des valeurs manquantes

# ‚úÖ Cr√©er une copie de df_ts_jour pour le traitement
df_results <- data.frame(
  index = time(df_ts_jour),  # Conserve l'index temporel
  value = as.numeric(df_ts_jour)  # Convertit en valeurs num√©riques
)

# ‚úÖ Remplacement des valeurs probl√©matiques (NA, Inf, Z√©ros)
df_results <- df_results %>%
  mutate(value = replace(value, value == 0, 1e-10)) %>%  # Remplace les 0 par une tr√®s petite valeur
  mutate(value = ifelse(value < 0, NA, value)) %>%  # Convertit les valeurs n√©gatives en NA
  mutate(value = na.approx(value, na.rm = FALSE)) %>%  # Interpolation des valeurs NA
  filter(!is.infinite(value))  # Supprime les valeurs infinies

# ‚úÖ D√©finir les degr√©s √† tester
degrees <- 1:20  # Tester des polyn√¥mes de degr√© 1 √† 20
aic_values <- numeric(length(degrees))
bic_values <- numeric(length(degrees))
rmse_values <- numeric(length(degrees))
mae_values <- numeric(length(degrees))

# ‚úÖ Boucle pour ajuster les mod√®les polynomiaux
for (i in degrees) {
  fit_poly <- lm(log(value) ~ poly(index, i, raw = TRUE), data = df_results)
  predictions <- exp(predict(fit_poly, newdata = df_results))

  residuals <- df_results$value - predictions
  rmse_values[i] <- sqrt(mean(residuals^2, na.rm = TRUE))
  mae_values[i] <- mean(abs(residuals), na.rm = TRUE)
  aic_values[i] <- AIC(fit_poly)
  bic_values[i] <- BIC(fit_poly)
}

# ‚úÖ S√©lection du meilleur degr√© bas√© sur AIC et BIC combin√©s
optimal_degree_poly <- degrees[which.min(aic_values + bic_values)]
best_aic <- min(aic_values)
best_bic <- min(bic_values)
best_rmse <- min(rmse_values)
best_mae <- min(mae_values)

# ‚úÖ Mise √† l'√©chelle des valeurs pour un meilleur affichage
df_errors <- data.frame(Degree = degrees, AIC = aic_values, BIC = bic_values, RMSE = rmse_values, MAE = mae_values) %>%
  mutate(AIC_norm = (AIC - min(AIC)) / (max(AIC) - min(AIC)),
         BIC_norm = (BIC - min(BIC)) / (max(BIC) - min(BIC)),
         RMSE_norm = (RMSE - min(RMSE)) / (max(RMSE) - min(RMSE)),
         MAE_norm = (MAE - min(MAE)) / (max(MAE) - min(MAE)))

# ‚úÖ Affichage des valeurs des crit√®res pour chaque degr√©
df_errors %>%
  select(Degree, AIC, BIC, RMSE, MAE) %>%
  mutate(AIC = round(AIC, 2),
         BIC = round(BIC, 2),
         RMSE = round(RMSE, 2),
         MAE = round(MAE, 2)) %>%
  print()

# ‚úÖ Affichage du r√©sum√© du mod√®le s√©lectionn√©
fit_poly_best <- lm(log(value) ~ poly(index, optimal_degree_poly, raw = TRUE), data = df_results)
summary(fit_poly_best)

# ‚úÖ Affichage du degr√© optimal et ses valeurs correspondantes
cat("‚úÖ Degr√© optimal s√©lectionn√© :", optimal_degree_poly, "\n")
cat("üìä AIC :", round(best_aic, 2), "\n")
cat("üìä BIC :", round(best_bic, 2), "\n")
cat("üìä RMSE :", round(best_rmse, 2), "\n")
cat("üìä MAE :", round(best_mae, 2), "\n")

# ‚úÖ üìä Graphique comparatif des crit√®res avec √©chelle normalis√©e
ggplot(df_errors, aes(x = Degree)) +
  geom_point(aes(y = AIC_norm, color = "AIC"), size = 3) +
  geom_point(aes(y = BIC_norm, color = "BIC"), size = 3) +
  geom_point(aes(y = RMSE_norm, color = "RMSE"), size = 3) +
  geom_point(aes(y = MAE_norm, color = "MAE"), size = 3) +
  
  geom_line(aes(y = AIC_norm, color = "AIC"), size = 1) +
  geom_line(aes(y = BIC_norm, color = "BIC"), size = 1) +
  geom_line(aes(y = RMSE_norm, color = "RMSE"), size = 1) +
  geom_line(aes(y = MAE_norm, color = "MAE"), size = 1) +
  
  labs(title = "S√©lection du Degr√© Optimal (Mod√®le Polynomial)",
       x = "Degr√©",
       y = "Crit√®res (√©chelle normalis√©e)") +
  scale_color_manual(values = c("AIC" = "blue", "BIC" = "red", "RMSE" = "green", "MAE" = "orange")) +
  theme_minimal()

# ‚úÖ Application du meilleur mod√®le polynomial
df_results$Pred_Poly <- exp(predict(fit_poly_best, newdata = df_results))

# ‚úÖ üìä Graphique du mod√®le Polynomial optimal appliqu√© √† la s√©rie
ggplot(df_results, aes(x = index)) +
  geom_line(aes(y = value, color = "S√©rie Originale"), size = 1) +
  geom_line(aes(y = Pred_Poly, color = "Mod√®le Polynomial"), size = 1.2) +
  labs(title = paste("Meilleur Mod√®le Polynomial (Degr√©", optimal_degree_poly, ") Appliqu√© √† la S√©rie"),
       x = "Index",
       y = "Valeur de la S√©rie") +
  scale_color_manual(values = c("S√©rie Originale" = "black", "Mod√®le Polynomial" = "blue")) +
  theme_minimal()

# ‚úÖ Conserver df_ts_jour en tant que s√©rie temporelle
df_ts_jour <- ts(df_results$value, start = start(df_ts_jour), frequency = frequency(df_ts_jour))
pred_ts <- ts(df_results$Pred_Poly, start = start(df_ts_jour), frequency = frequency(df_ts_jour))

```

## Additive model, GAM

Le mod√®le GAM permet de mod√©liser des relations non lin√©aires complexes en utilisant des fonctions de lissage.

$$
Y_t = \beta_0 + f(t) + \epsilon_t
$$

-   $f(t)$ : une fonction de lissage (par exemple une spline)\

-   $\beta_0$ : l'ordonn√©e √† l'origine\

-   $\epsilon_t$ : le terme d'erreur

-   Les termes liss√©s sont significatifs (p-value \< 0.001), avec une deviance expliqu√©e de 18 % et un R¬≤ ajust√© de 0.175.

-   Les valeurs associ√©es √† la signification approximative des termes liss√©s montrent une contribution importante (edf = 8.503, F = 31.17)

Le GAM capture mieux les tendances non lin√©aires qu‚Äôun mod√®le lin√©aire ou polynomial simple. Cependant, la proportion de variance expliqu√©e reste modeste, sugg√©rant que des facteurs additionnels ou des dynamiques complexes influencent les donn√©es.

```{r}
# üìå Charger les biblioth√®ques n√©cessaires
library(ggplot2)
library(mgcv)
library(dplyr)
library(zoo)  # Pour l'interpolation des valeurs manquantes

# ‚úÖ Cr√©er une copie de df_ts_jour pour le traitement
df_results <- data.frame(
  index = time(df_ts_jour),  # Conserve l'index temporel
  value = as.numeric(df_ts_jour)  # Convertit en valeurs num√©riques
)

# ‚úÖ Remplacement des valeurs probl√©matiques (NA, Inf, Z√©ros)
df_results <- df_results %>%
  mutate(value = replace(value, value == 0, 1e-10)) %>%  # Remplace les 0 par une tr√®s petite valeur
  mutate(value = ifelse(value < 0, NA, value)) %>%  # Convertit les valeurs n√©gatives en NA
  mutate(value = na.approx(value, na.rm = FALSE)) %>%  # Interpolation des valeurs NA
  filter(!is.infinite(value))  # Supprime les valeurs infinies

# ‚úÖ D√©finition des param√®tres de lissage √† tester
smooth_params <- seq(3, 20, by = 1)  # Tester de k = 3 √† k = 20
aic_values <- numeric(length(smooth_params))
bic_values <- numeric(length(smooth_params))
rmse_values <- numeric(length(smooth_params))
mae_values <- numeric(length(smooth_params))

# ‚úÖ Boucle pour ajuster les mod√®les GAM avec diff√©rents param√®tres de lissage
for (i in seq_along(smooth_params)) {
  k_val <- smooth_params[i]
  
  tryCatch({
    fit_gam <- gam(value ~ s(index, bs = "cs", k = min(k_val, nrow(df_results) - 1)), data = df_results)
    predictions <- predict(fit_gam, newdata = df_results)

    residuals <- df_results$value - predictions
    rmse_values[i] <- sqrt(mean(residuals^2, na.rm = TRUE))
    mae_values[i] <- mean(abs(residuals), na.rm = TRUE)
    aic_values[i] <- AIC(fit_gam)
    bic_values[i] <- BIC(fit_gam)

  }, error = function(e) {
    cat("‚ùå Erreur √† k =", k_val, ": ", e$message, "\n")
    aic_values[i] <- NA
    bic_values[i] <- NA
    rmse_values[i] <- NA
    mae_values[i] <- NA
  })
}

# ‚úÖ S√©lection du meilleur param√®tre bas√© sur AIC et BIC combin√©s
optimal_smooth_gam <- smooth_params[which.min(aic_values + bic_values)]
best_aic <- min(aic_values, na.rm = TRUE)
best_bic <- min(bic_values, na.rm = TRUE)
best_rmse <- min(rmse_values, na.rm = TRUE)
best_mae <- min(mae_values, na.rm = TRUE)

# ‚úÖ Affichage des valeurs optimales du mod√®le s√©lectionn√©
cat("\n‚úÖ Param√®tre de lissage optimal s√©lectionn√© : k =", optimal_smooth_gam, "\n")
cat("üìä AIC :", round(best_aic, 2), "\n")
cat("üìä BIC :", round(best_bic, 2), "\n")
cat("üìä RMSE :", round(best_rmse, 2), "\n")
cat("üìä MAE :", round(best_mae, 2), "\n")

# ‚úÖ Normalisation des valeurs pour une meilleure visibilit√©
df_errors <- data.frame(SmoothParam = smooth_params, AIC = aic_values, BIC = bic_values, RMSE = rmse_values, MAE = mae_values) %>%
  mutate(AIC_norm = (AIC - min(AIC, na.rm = TRUE)) / (max(AIC, na.rm = TRUE) - min(AIC, na.rm = TRUE)),
         BIC_norm = (BIC - min(BIC, na.rm = TRUE)) / (max(BIC, na.rm = TRUE) - min(BIC, na.rm = TRUE)),
         RMSE_norm = (RMSE - min(RMSE, na.rm = TRUE)) / (max(RMSE, na.rm = TRUE) - min(RMSE, na.rm = TRUE)),
         MAE_norm = (MAE - min(MAE, na.rm = TRUE)) / (max(MAE, na.rm = TRUE) - min(MAE, na.rm = TRUE)))

# ‚úÖ Affichage des valeurs des crit√®res pour chaque param√®tre de lissage
df_errors %>%
  select(SmoothParam, AIC, BIC, RMSE, MAE) %>%
  mutate(AIC = round(AIC, 2),
         BIC = round(BIC, 2),
         RMSE = round(RMSE, 2),
         MAE = round(MAE, 2)) %>%
  print()
# üìä üìå Graphique de s√©lection du param√®tre optimal avec mise √† l'√©chelle
ggplot(df_errors, aes(x = SmoothParam)) +
  geom_line(aes(y = AIC_norm, color = "AIC"), size = 1) +
  geom_line(aes(y = BIC_norm, color = "BIC"), size = 1) +
  geom_line(aes(y = RMSE_norm, color = "RMSE"), size = 1) +
  geom_line(aes(y = MAE_norm, color = "MAE"), size = 1) +
  labs(title = "S√©lection du Meilleur Param√®tre de Lissage (GAM)",
       x = "Param√®tre de lissage k",
       y = "Valeur Normalis√©e des Crit√®res") +
  scale_color_manual(values = c("AIC" = "blue", "BIC" = "red", "RMSE" = "green", "MAE" = "orange")) +
  theme_minimal()

# ‚úÖ Ajustement du meilleur mod√®le GAM
fit_gam_best <- gam(value ~ s(index, bs = "cs", k = optimal_smooth_gam), data = df_results)
summary(fit_gam_best)

# ‚úÖ Application du mod√®le GAM optimal √† la s√©rie
df_results$Pred_GAM <- predict(fit_gam_best, newdata = df_results)

# üìä üìå Graphique du mod√®le GAM optimal appliqu√© √† la s√©rie
ggplot(df_results, aes(x = index)) +
  geom_line(aes(y = value, color = "S√©rie Originale"), size = 1) +
  geom_line(aes(y = Pred_GAM, color = "Mod√®le GAM"), size = 1.2) +
  labs(title = paste("Meilleur Mod√®le GAM (k =", optimal_smooth_gam, ") Appliqu√© √† la S√©rie"),
       x = "Index",
       y = "Valeur de la S√©rie") +
  scale_color_manual(values = c("S√©rie Originale" = "black", "Mod√®le GAM" = "goldenrod")) +
  theme_minimal()

# ‚úÖ Conserver df_ts_jour en tant que s√©rie temporelle
df_ts_jour <- ts(df_results$value, start = start(df_ts_jour), frequency = frequency(df_ts_jour))
pred_ts_gam <- ts(df_results$Pred_GAM, start = start(df_ts_jour), frequency = frequency(df_ts_jour))

```

## Bspline regression

La r√©gression B-Spline utilise des fonctions de base spline pour mod√©liser des courbes flexibles et ajust√©es aux donn√©es.

$$
Y_t = \beta_0 + \sum_{j=1}^k \beta_j B_j(t) + \epsilon_t
$$

-   $B_j(t)$ : les fonctions de base spline (B-splines)\

-   $k$ : le nombre de fonctions de base spline\

-   $\beta_j$ : les coefficients associ√©s aux splines\

-   $\epsilon_t$ : le terme d'erreur

-   Les coefficients estim√©s des splines sont significatifs, avec des p-values tr√®s faibles (\< 0.05), indiquant une bonne capture des variations.

-   R¬≤ ajust√© = 0.151, F-statistic = 46.99, p-value \< 2.2e-16.

-   Le r√©sidu standard (43630000) montre que des erreurs importantes persistent malgr√© l‚Äôajustement

La r√©gression B-spline offre une mod√©lisation flexible, mais la proportion de variance expliqu√©e (R¬≤ ajust√© faible) indique que des structures non mod√©lis√©es persistent dans les donn√©es.

```{r}
# üìå Charger les biblioth√®ques n√©cessaires
library(ggplot2)
library(splines)
library(dplyr)
library(zoo)  # Pour interpolation des valeurs manquantes

# ‚úÖ Cr√©er une copie de df_ts_jour pour le traitement
df_results <- data.frame(
  index = time(df_ts_jour),  # Conserve l'index temporel
  value = as.numeric(df_ts_jour)  # Convertit en valeurs num√©riques
)

# ‚úÖ Remplacement des valeurs probl√©matiques (NA, Inf, Z√©ros)
df_results <- df_results %>%
  mutate(value = replace(value, value == 0, 1e-10)) %>%  # Remplace les 0 par une tr√®s petite valeur
  mutate(value = ifelse(value < 0, NA, value)) %>%  # Convertit les valeurs n√©gatives en NA
  mutate(value = na.approx(value, na.rm = FALSE)) %>%  # Interpolation des valeurs NA
  filter(!is.infinite(value))  # Supprime les valeurs infinies

# ‚úÖ D√©finir les degr√©s √† tester
degrees <- 1:20  # Tester B-Spline de degr√© 1 √† 20
aic_values <- numeric(length(degrees))
bic_values <- numeric(length(degrees))
rmse_values <- numeric(length(degrees))
mae_values <- numeric(length(degrees))

# ‚úÖ Boucle pour ajuster les mod√®les B-Spline avec diff√©rents degr√©s
for (i in degrees) {
  tryCatch({
    fit_bspline <- lm(value ~ bs(index, df = i), data = df_results)
    predictions <- predict(fit_bspline, newdata = df_results)

    residuals <- df_results$value - predictions
    rmse_values[i] <- sqrt(mean(residuals^2, na.rm = TRUE))
    mae_values[i] <- mean(abs(residuals), na.rm = TRUE)
    aic_values[i] <- AIC(fit_bspline)
    bic_values[i] <- BIC(fit_bspline)

  }, error = function(e) {
    cat("‚ùå Erreur √† df =", i, ": ", e$message, "\n")
    aic_values[i] <- NA
    bic_values[i] <- NA
    rmse_values[i] <- NA
    mae_values[i] <- NA
  })
}

# ‚úÖ S√©lection du meilleur degr√© bas√© sur AIC et BIC combin√©s
optimal_degree_bspline <- degrees[which.min(aic_values + bic_values)]
best_aic <- min(aic_values, na.rm = TRUE)
best_bic <- min(bic_values, na.rm = TRUE)
best_rmse <- min(rmse_values, na.rm = TRUE)
best_mae <- min(mae_values, na.rm = TRUE)

# ‚úÖ Affichage des valeurs optimales du mod√®le s√©lectionn√©
cat("\n‚úÖ Degr√© optimal s√©lectionn√© : df =", optimal_degree_bspline, "\n")
cat("üìä AIC :", round(best_aic, 2), "\n")
cat("üìä BIC :", round(best_bic, 2), "\n")
cat("üìä RMSE :", round(best_rmse, 2), "\n")
cat("üìä MAE :", round(best_mae, 2), "\n")

# ‚úÖ Normalisation des valeurs pour une meilleure visibilit√©
df_errors <- data.frame(Degree = degrees, AIC = aic_values, BIC = bic_values, RMSE = rmse_values, MAE = mae_values) %>%
  mutate(AIC_norm = (AIC - min(AIC, na.rm = TRUE)) / (max(AIC, na.rm = TRUE) - min(AIC, na.rm = TRUE)),
         BIC_norm = (BIC - min(BIC, na.rm = TRUE)) / (max(BIC, na.rm = TRUE) - min(BIC, na.rm = TRUE)),
         RMSE_norm = (RMSE - min(RMSE, na.rm = TRUE)) / (max(RMSE, na.rm = TRUE) - min(RMSE, na.rm = TRUE)),
         MAE_norm = (MAE - min(MAE, na.rm = TRUE)) / (max(MAE, na.rm = TRUE) - min(MAE, na.rm = TRUE)))

# ‚úÖ Affichage des valeurs des crit√®res pour chaque degr√©
df_errors %>%
  select(Degree, AIC, BIC, RMSE, MAE) %>%
  mutate(AIC = round(AIC, 2),
         BIC = round(BIC, 2),
         RMSE = round(RMSE, 2),
         MAE = round(MAE, 2)) %>%
  print()

# üìä üìå Graphique de s√©lection du degr√© optimal avec mise √† l'√©chelle
ggplot(df_errors, aes(x = Degree)) +
  geom_line(aes(y = AIC_norm, color = "AIC"), size = 1) +
  geom_line(aes(y = BIC_norm, color = "BIC"), size = 1) +
  geom_line(aes(y = RMSE_norm, color = "RMSE"), size = 1) +
  geom_line(aes(y = MAE_norm, color = "MAE"), size = 1) +
  labs(title = "S√©lection du Meilleur Degr√© (B-Spline)",
       x = "Degr√© (df)",
       y = "Valeur Normalis√©e des Crit√®res") +
  scale_color_manual(values = c("AIC" = "blue", "BIC" = "red", "RMSE" = "green", "MAE" = "orange")) +
  theme_minimal()

# ‚úÖ Ajustement du meilleur mod√®le B-Spline
fit_bspline_best <- lm(value ~ bs(index, df = optimal_degree_bspline), data = df_results)
summary(fit_bspline_best)

# ‚úÖ Application du mod√®le B-Spline optimal √† la s√©rie
df_results$Pred_BSpline <- predict(fit_bspline_best, newdata = df_results)

# üìä üìå Graphique du mod√®le B-Spline optimal appliqu√© √† la s√©rie
ggplot(df_results, aes(x = index)) +
  geom_line(aes(y = value, color = "S√©rie Originale"), size = 1) +
  geom_line(aes(y = Pred_BSpline, color = "Mod√®le B-Spline"), size = 1.2) +
  labs(title = paste("Meilleur Mod√®le B-Spline (df =", optimal_degree_bspline, ") Appliqu√© √† la S√©rie"),
       x = "Index",
       y = "Valeur de la S√©rie") +
  scale_color_manual(values = c("S√©rie Originale" = "black", "Mod√®le B-Spline" = "red")) +
  theme_minimal()

# ‚úÖ Conserver df_ts_jour en tant que s√©rie temporelle
df_ts_jour <- ts(df_results$value, start = start(df_ts_jour), frequency = frequency(df_ts_jour))
pred_ts_bspline <- ts(df_results$Pred_BSpline, start = start(df_ts_jour), frequency = frequency(df_ts_jour))


```

## Conclusion des m√©thodes de r√©gression

| Mod√®le | AIC | BIC | RMSE | MAE |
|---------------|---------------|---------------|---------------|---------------|
| R√©gression lin√©aire | 49374.59 | 49390.09 | 46595968 | 25596043 |
| R√©gression polynomiale (degr√© 4) | 6185.546 | 6216.539 | 48816763 | 21721011 |
| [GAM]{style="color:green; font-weight:bold"} | [49172.65]{style="color:green; font-weight:bold"} | [49226.91]{style="color:green; font-weight:bold"} | [42849160]{style="color:green; font-weight:bold"} | [21611490]{style="color:green; font-weight:bold"} |
| B-Spline (degr√© 1) | 49190.34 | 49221.33 | 43293439 | 21585093 |

Le GAM offre un compromis solide : ‚Ä¢ Bon √©quilibre entre AIC/BIC (proches du meilleur). ‚Ä¢ Meilleur RMSE (pr√©cision √©lev√©e). ‚Ä¢ Un MAE proche du meilleur.

## graphique

```{r}
# üìå Charger les biblioth√®ques n√©cessaires
library(ggplot2)
library(plotly)
library(dplyr)
library(mgcv)    # Pour GAM
library(splines) # Pour B-Spline
library(zoo)     # Pour la moyenne mobile
library(tsibble)

# ‚úÖ Cr√©ation d'une copie de la s√©rie temporelle originale avant modifications
df_ts_lissage <- df_ts_jour  

# ‚úÖ V√©rifier si `df_ts_jour` est une s√©rie temporelle et convertir en data.frame pour le traitement
if (is.ts(df_ts_jour)) {
  start_year <- start(df_ts_jour)[1]
  start_day <- start(df_ts_jour)[2]
  df_ts_jour_df <- data.frame(
    index = seq.Date(from = as.Date(paste0(start_year, "-01-01")), 
                     length.out = length(df_ts_jour), by = "day"),
    value = as.numeric(df_ts_jour)
  )
} else {
  df_ts_jour_df <- df_ts_jour  # Si ce n'est pas une s√©rie temporelle, on l'utilise tel quel
}

# ‚úÖ Conversion en tsibble pour analyse
df_ts_jour_df <- df_ts_jour_df %>%
  mutate(index = as.Date(index)) %>%
  as_tsibble(index = index)

# ‚úÖ Cr√©ation du DataFrame pour stocker les r√©sultats des mod√®les
df_results <- data.frame(Time = df_ts_jour_df$index, Observ√© = df_ts_jour_df$value)

# ‚úÖ Convertir Time en num√©rique pour les mod√®les
df_results$Time <- as.numeric(df_results$Time)

# üìå **Mod√®les de R√©gression avec les param√®tres optimaux**

# ‚úÖ 1Ô∏è‚É£ R√©gression Lin√©aire
fit_lin <- lm(Observ√© ~ Time, data = df_results)
df_results$Pred_Lin <- predict(fit_lin)

# ‚úÖ 2Ô∏è‚É£ R√©gression Polyn√¥miale (Degr√© 4)
fit_poly4 <- lm(log(Observ√©) ~ poly(Time, 4, raw = TRUE), data = df_results)
df_results$Pred_Poly <- exp(predict(fit_poly4))

# ‚úÖ 3Ô∏è‚É£ Mod√®le GAM (Param√®tre de lissage k = 8)
fit_gam <- gam(Observ√© ~ s(Time, bs = "cs", k = 8), data = df_results)
df_results$Pred_GAM <- predict(fit_gam)

# ‚úÖ 4Ô∏è‚É£ Mod√®le B-Spline (Degr√© 9)
fit_bspline <- lm(Observ√© ~ bs(Time, df = 9), data = df_results)
df_results$Pred_BSpline <- predict(fit_bspline)

# üìä **Cr√©ation du graphique interactif avec ggplot2**
p <- ggplot(df_results, aes(x = as.Date(Time, origin = "1970-01-01"))) +  
  geom_line(aes(y = Observ√©, color = "S√©rie R√©elle"), size = 0.8) + 
  geom_line(aes(y = Pred_Lin, color = "R√©gression Lin√©aire"), size = 0.9) +
  geom_line(aes(y = Pred_Poly, color = "R√©gression Polyn√¥miale (Degr√© 4)"), size = 0.9) +
  geom_line(aes(y = Pred_GAM, color = "Mod√®le GAM (k=8)"), size = 0.9) +
  geom_line(aes(y = Pred_BSpline, color = "B-Spline (Degr√© 9)"), size = 0.9) +

  # ‚úÖ Mise en forme des axes
  scale_x_date(date_breaks = "1 year", date_labels = "%Y") +
  scale_y_continuous(labels = scales::comma) +

  # ‚úÖ Attribution des couleurs aux mod√®les
  scale_color_manual(values = c(
    "S√©rie R√©elle" = "black",
    "R√©gression Lin√©aire" = "green",
    "R√©gression Polyn√¥miale (Degr√© 4)" = "blue",
    "Mod√®le GAM (k=8)" = "goldenrod",
    "B-Spline (Degr√© 9)" = "red"
  )) +

  # ‚úÖ Ajout de titres et l√©gendes
  labs(title = "Comparaison des Mod√®les de R√©gression (Param√®tres Optimaux)",
       x = "Ann√©e",
       y = "Valeur de la S√©rie",
       color = "Mod√®les") +

  # ‚úÖ Style graphique
  theme_minimal() +
  theme(plot.title = element_text(face = "bold", hjust = 0.5, size = 14),
        axis.title = element_text(face = "bold"),
        legend.position = "right")

# üìå Transformer en graphique interactif avec `plotly`
ggplotly(p) %>%
  layout(legend = list(orientation = "v", x = 1, y = 0.5))

# ‚úÖ **Reconstruire `df_ts_jour` comme s√©rie temporelle apr√®s analyse**
df_ts_jour <- ts(df_ts_jour_df$value, start = start(df_ts_lissage), frequency = frequency(df_ts_lissage))

# ‚úÖ **Reconstruire les pr√©dictions comme s√©ries temporelles**
pred_ts_poly <- ts(df_results$Pred_Poly, start = start(df_ts_lissage), frequency = frequency(df_ts_lissage))
pred_ts_gam <- ts(df_results$Pred_GAM, start = start(df_ts_lissage), frequency = frequency(df_ts_lissage))
pred_ts_bspline <- ts(df_results$Pred_BSpline, start = start(df_ts_lissage), frequency = frequency(df_ts_lissage))
pred_ts_lin <- ts(df_results$Pred_Lin, start = start(df_ts_lissage), frequency = frequency(df_ts_lissage))

```

# M√©thodes de lissage

Les m√©thodes de lissage (LOESS, lissage exponentiel simple et double, moyenne mobile) sont utilis√©es pour r√©duire le bruit des fluctuations al√©atoires et identifier des tendances locales.

## Local polynomial

La r√©gression locale polynomiale (ou LOESS/LOWESS) est une m√©thode non param√©trique utilis√©e pour ajuster une courbe aux donn√©es en effectuant des r√©gressions polynomiales locales sur des fen√™tres glissantes. Elle est particuli√®rement utile pour capturer des tendances locales non lin√©aires dans les s√©ries chronologiques.

$$
\hat{Y}_t = \sum_{j=0}^d \hat{\beta}_j t^j, \quad \text{o√π} \quad \sum_{i=1}^n W_i (Y_i - \hat{\beta}_0 - \hat{\beta}_1 t_i - \ldots - \hat{\beta}_d t_i^d)^2 \text{ est minimis√©.}
$$

-   $t$ : le point o√π l‚Äôestimation est faite.\
-   $d$ : le degr√© du polyn√¥me local (typiquement $d = 1$ ou $d = 2$).\
-   $W_i$ : les poids attribu√©s aux observations $Y_i$, souvent d√©finis par une fonction noyau (ex. noyau tricube).\
-   $\hat{\beta}_j$ : les coefficients du polyn√¥me ajust√© localement.\
-   $n$ : le nombre total d'observations dans la fen√™tre locale.\
-   $Y_i$ : les valeurs de la s√©rie chronologique associ√©es √† chaque point $t_i$.\
-   **Fen√™tre (span)** : proportion des points inclus dans la r√©gression locale (ex. 0.5 pour inclure 50 % des points voisins).

```{r}
#print(df_ts_jour)
```

```{r}
# üìå Charger les biblioth√®ques n√©cessaires
library(ggplot2)
library(dplyr)
library(zoo)  # Pour interpolation des valeurs manquantes

# ‚úÖ Cr√©er une copie de df_ts_jour pour le traitement sans modifier l'original
df_results <- data.frame(
  index = time(df_ts_jour),  # Conserve l'index temporel
  value = as.numeric(df_ts_jour)  # Convertit en valeurs num√©riques
)

# ‚úÖ Remplacement des valeurs probl√©matiques (NA, Inf, Z√©ros)
df_results <- df_results %>%
  mutate(value = replace(value, value == 0, 1e-10)) %>%  # Remplace les 0 par une tr√®s petite valeur
  mutate(value = ifelse(value < 0, NA, value)) %>%  # Convertit les valeurs n√©gatives en NA
  mutate(value = na.approx(value, na.rm = FALSE)) %>%  # Interpolation des valeurs NA
  filter(!is.infinite(value))  # Supprime les valeurs infinies

# ‚úÖ D√©finition des param√®tres de lissage LOESS √† tester (de 1 √† 20)
span_values <- seq(1, 20, by = 1)  # Param√®tres de lissage entre 1 et 20
aic_values <- numeric(length(span_values))
bic_values <- numeric(length(span_values))
rmse_values <- numeric(length(span_values))
mae_values <- numeric(length(span_values))

# üìå Boucle pour ajuster les mod√®les LOESS avec diff√©rentes valeurs de `span`
for (i in seq_along(span_values)) {
  span_val <- span_values[i] / 20  # Normalisation du param√®tre
  
  tryCatch({
    fit_loess <- loess(value ~ index, data = df_results, span = span_val, degree = 2)
    
    predictions <- predict(fit_loess, newdata = df_results)
    residuals <- df_results$value - predictions

    # V√©rification si les pr√©dictions contiennent des NA avant calcul des crit√®res
    if (all(!is.na(predictions))) {
      rmse_values[i] <- sqrt(mean(residuals^2, na.rm = TRUE))
      mae_values[i] <- mean(abs(residuals), na.rm = TRUE)

      # Calcul manuel de AIC et BIC pour LOESS
      n <- nrow(df_results)
      rss <- sum(residuals^2)
      k <- fit_loess$trace.hat  # Nombre effectif de param√®tres
      aic_values[i] <- n * log(rss / n) + 2 * k
      bic_values[i] <- n * log(rss / n) + k * log(n)

      # ‚úÖ Affichage des crit√®res pour chaque param√®tre test√©
      cat(sprintf("Span = %2d | AIC = %10.2f | BIC = %10.2f | RMSE = %10.4f | MAE = %10.4f\n", 
                  span_values[i], aic_values[i], bic_values[i], rmse_values[i], mae_values[i]))

    } else {
      rmse_values[i] <- NA
      mae_values[i] <- NA
      aic_values[i] <- NA
      bic_values[i] <- NA
    }
  }, error = function(e) {
    cat("‚ùå Erreur √† span =", span_val, ": ", e$message, "\n")
    aic_values[i] <- NA
    bic_values[i] <- NA
    rmse_values[i] <- NA
    mae_values[i] <- NA
  })
}

# ‚úÖ Normalisation des valeurs entre 0 et 1 pour l'affichage
normalize <- function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))

df_errors <- data.frame(Span = span_values, 
                        AIC = normalize(aic_values),
                        BIC = normalize(bic_values),
                        RMSE = normalize(rmse_values),
                        MAE = normalize(mae_values))

# ‚úÖ S√©lection du meilleur param√®tre bas√© sur AIC et BIC combin√©s
optimal_span_loess <- span_values[which.min(aic_values + bic_values)]
best_aic <- min(aic_values, na.rm = TRUE)
best_bic <- min(bic_values, na.rm = TRUE)
best_rmse <- min(rmse_values, na.rm = TRUE)
best_mae <- min(mae_values, na.rm = TRUE)

# ‚úÖ Affichage structur√© des r√©sultats
cat("\nüîπ **S√©lection du Mod√®le LOESS Optimal** üîπ\n")
cat("‚úÖ **Le param√®tre de lissage optimal s√©lectionn√© est : span =", round(optimal_span_loess, 2), "**\n")
cat("üìä **Valeur du AIC :**", round(best_aic, 2), "\n")
cat("üìä **Valeur du BIC :**", round(best_bic, 2), "\n")
cat("üìä **Valeur du RMSE :**", round(best_rmse, 2), "\n")
cat("üìä **Valeur du MAE :**", round(best_mae, 2), "\n\n")

# üìä üìå Graphique de s√©lection du param√®tre optimal avec **valeurs entre 0 et 1**
ggplot(df_errors, aes(x = Span)) +
  geom_line(aes(y = AIC, color = "AIC"), size = 1) +
  geom_line(aes(y = BIC, color = "BIC"), size = 1) +
  geom_line(aes(y = RMSE, color = "RMSE"), size = 1) +
  geom_line(aes(y = MAE, color = "MAE"), size = 1) +
  labs(title = "S√©lection du Meilleur Param√®tre de Lissage (LOESS)",
       x = "Param√®tre de lissage (1-20)",
       y = "Valeur des Crit√®res (Normalis√©)") +
  scale_color_manual(values = c("AIC" = "blue", "BIC" = "red", "RMSE" = "green", "MAE" = "orange")) +
  xlim(0, 20) + ylim(0, 1) +  # ‚úÖ Forcer les axes entre 0 et 20 (X) et 0 et 1 (Y)
  theme_minimal()

# ‚úÖ Ajustement du mod√®le LOESS optimal
fit_loess_best <- loess(value ~ index, data = df_results, span = optimal_span_loess / 20, degree = 2)
summary(fit_loess_best)

# ‚úÖ Application du mod√®le LOESS optimal √† la s√©rie
df_results$Pred_LOESS <- predict(fit_loess_best, newdata = df_results)

# üìä üìå Graphique du mod√®le LOESS optimal appliqu√© √† la s√©rie
ggplot(df_results, aes(x = index)) +
  geom_line(aes(y = value, color = "S√©rie Originale"), size = 1) +
  geom_line(aes(y = Pred_LOESS, color = "Mod√®le LOESS"), size = 1.2) +
  labs(title = paste("Meilleur Mod√®le LOESS (span =", round(optimal_span_loess, 2), ") Appliqu√© √† la S√©rie"),
       x = "Index",
       y = "Valeur de la S√©rie") +
  scale_color_manual(values = c("S√©rie Originale" = "black", "Mod√®le LOESS" = "blue")) +
  theme_minimal()

# ‚úÖ Conserver df_ts_jour en tant que s√©rie temporelle
df_ts_jour <- ts(df_results$value, start = start(df_ts_jour), frequency = frequency(df_ts_jour))
pred_ts_loess <- ts(df_results$Pred_LOESS, start = start(df_ts_jour), frequency = frequency(df_ts_jour))

```

## Moyenne mobile

La moyenne mobile est une m√©thode utilis√©e pour lisser une s√©rie chronologique en calculant la moyenne des valeurs sur une fen√™tre glissante de taille k . Elle est simple √† mettre en ≈ìuvre et aide √† att√©nuer les fluctuations al√©atoires pour mieux observer les tendances sous-jacentes.

$$
\hat{Y}_t = \frac{1}{k} \sum_{i=t-\frac{k-1}{2}}^{t+\frac{k-1}{2}} Y_i
$$ - $t$ : l‚Äôinstant o√π l‚Äôestimation est faite.\
- $k$ : la taille de la fen√™tre (doit √™tre impair pour centrer la fen√™tre autour de $t$).\
- $Y_i$ : les valeurs de la s√©rie chronologique dans la fen√™tre glissante.\
- **Bords (fill)** : comment g√©rer les bords de la s√©rie (par exemple, `NA` pour des valeurs manquantes).

### S√©lection du d√©gre optimal

```{r}
# üìå Charger les biblioth√®ques n√©cessaires
library(ggplot2)
library(dplyr)
library(zoo)  # Pour calculer la moyenne mobile

# ‚úÖ Cr√©er une copie de df_ts_jour pour le traitement sans modifier l'original
df_results <- data.frame(
  index = time(df_ts_jour),  # Conserve l'index temporel
  value = as.numeric(df_ts_jour)  # Convertit en valeurs num√©riques
)

# ‚úÖ Remplacement des valeurs probl√©matiques (NA, Inf, Z√©ros)
df_results <- df_results %>%
  mutate(value = replace(value, value == 0, 1e-10)) %>%  # Remplace les 0 par une tr√®s petite valeur
  mutate(value = ifelse(value < 0, NA, value)) %>%  # Convertit les valeurs n√©gatives en NA
  mutate(value = na.approx(value, na.rm = FALSE)) %>%  # Interpolation des valeurs NA
  filter(!is.infinite(value))  # Supprime les valeurs infinies

# ‚úÖ D√©finition des fen√™tres de lissage √† tester (de 1 √† 20 jours)
window_sizes <- 1:20
aic_values <- numeric(length(window_sizes))
bic_values <- numeric(length(window_sizes))
rmse_values <- numeric(length(window_sizes))
mae_values <- numeric(length(window_sizes))

# üìå Boucle pour tester plusieurs valeurs de `window_size` pour la moyenne mobile
for (i in seq_along(window_sizes)) {
  window_size <- window_sizes[i]

  tryCatch({
    # Application de la moyenne mobile avec une fen√™tre de `window_size`
    df_results$moving_avg <- rollmean(df_results$value, k = window_size, fill = NA, align = "right")

    # Calcul des erreurs
    residuals <- df_results$value - df_results$moving_avg

    # V√©rification si les pr√©dictions contiennent des NA avant calcul des crit√®res
    if (all(!is.na(df_results$moving_avg))) {
      rmse_values[i] <- sqrt(mean(residuals^2, na.rm = TRUE))
      mae_values[i] <- mean(abs(residuals), na.rm = TRUE)

      # Calcul manuel de AIC et BIC
      n <- nrow(df_results)
      rss <- sum(residuals^2, na.rm = TRUE)
      k <- window_size  # Nombre effectif de param√®tres
      aic_values[i] <- n * log(rss / n) + 2 * k
      bic_values[i] <- n * log(rss / n) + k * log(n)
    } else {
      rmse_values[i] <- NA
      mae_values[i] <- NA
      aic_values[i] <- NA
      bic_values[i] <- NA
    }
  }, error = function(e) {
    cat("‚ùå Erreur pour window_size =", window_size, ": ", e$message, "\n")
    aic_values[i] <- NA
    bic_values[i] <- NA
    rmse_values[i] <- NA
    mae_values[i] <- NA
  })
}

# ‚úÖ Normalisation des valeurs entre 0 et 1 pour l'affichage
normalize <- function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))

df_errors <- data.frame(Window = window_sizes, 
                        AIC = normalize(aic_values),
                        BIC = normalize(bic_values),
                        RMSE = normalize(rmse_values),
                        MAE = normalize(mae_values))

# ‚úÖ S√©lection de la meilleure fen√™tre bas√©e sur AIC et BIC combin√©s
optimal_window_size <- window_sizes[which.min(aic_values + bic_values)]
best_aic <- min(aic_values, na.rm = TRUE)
best_bic <- min(bic_values, na.rm = TRUE)
best_rmse <- min(rmse_values, na.rm = TRUE)
best_mae <- min(mae_values, na.rm = TRUE)

# ‚úÖ Affichage structur√© des r√©sultats
cat("\nüîπ **S√©lection du Mod√®le Moyenne Mobile Optimal** üîπ\n")
cat("‚úÖ **La meilleure fen√™tre de lissage s√©lectionn√©e est : window =", optimal_window_size, "jours**\n")
cat("üìä **Valeur du AIC :**", round(best_aic, 2), "\n")
cat("üìä **Valeur du BIC :**", round(best_bic, 2), "\n")
cat("üìä **Valeur du RMSE :**", round(best_rmse, 2), "\n")
cat("üìä **Valeur du MAE :**", round(best_mae, 2), "\n\n")

# üìä üìå Graphique de s√©lection du param√®tre optimal avec **valeurs entre 0 et 1**
ggplot(df_errors, aes(x = Window)) +
  geom_line(aes(y = AIC, color = "AIC"), size = 1) +
  geom_line(aes(y = BIC, color = "BIC"), size = 1) +
  geom_line(aes(y = RMSE, color = "RMSE"), size = 1) +
  geom_line(aes(y = MAE, color = "MAE"), size = 1) +
  labs(title = "S√©lection du Meilleur Param√®tre de Lissage (Moyenne Mobile)",
       x = "Fen√™tre de lissage (jours)",
       y = "Valeur des Crit√®res (Normalis√©)") +
  scale_color_manual(values = c("AIC" = "blue", "BIC" = "red", "RMSE" = "green", "MAE" = "orange")) +
  xlim(0, 20) + ylim(0, 1) +  # ‚úÖ Forcer les axes entre 0 et 20 (X) et 0 et 1 (Y)
  theme_minimal()

# ‚úÖ Ajustement de la meilleure moyenne mobile
df_results$Pred_Moving_Avg <- rollmean(df_results$value, k = optimal_window_size, fill = NA, align = "right")

# üìä üìå Graphique du mod√®le Moyenne Mobile optimal appliqu√© √† la s√©rie
ggplot(df_results, aes(x = index)) +
  geom_line(aes(y = value, color = "S√©rie Originale"), size = 1) +
  geom_line(aes(y = Pred_Moving_Avg, color = "Moyenne Mobile"), size = 1.2) +
  labs(title = paste("Meilleure Moyenne Mobile (Fen√™tre =", optimal_window_size, "jours) Appliqu√©e √† la S√©rie"),
       x = "Index",
       y = "Valeur de la S√©rie") +
  scale_color_manual(values = c("S√©rie Originale" = "black", "Moyenne Mobile" = "blue")) +
  theme_minimal()

# ‚úÖ Conserver df_ts_jour en tant que s√©rie temporelle
df_ts_jour <- ts(df_results$value, start = start(df_ts_jour), frequency = frequency(df_ts_jour))
pred_ts_moving_avg <- ts(df_results$Pred_Moving_Avg, start = start(df_ts_jour), frequency = frequency(df_ts_jour))

```

1.  Lissage des donn√©es : ‚Ä¢ La m√©thode a r√©duit les fluctuations et simplifi√© la s√©rie chronologique pour identifier des tendances globales. ‚Ä¢ Cependant, les variations importantes persistent (max 367,962,095 contre une moyenne de 27,497,397 ).
2.  Mod√®le TSLM : ‚Ä¢ Bien que les coefficients soient significatifs, le faible R¬≤ ajust√© ( 0.0072 ) indique que le mod√®le lin√©aire ne capture qu‚Äôune infime partie de la variabilit√© des donn√©es. ‚Ä¢ Cela sugg√®re que des tendances plus complexes ou des structures non lin√©aires sont pr√©sentes dans la s√©rie.

## Lissage exponentiel

Les m√©thodes de lissages exponentiels permettent de prolonger une s√©rie chronologique en vue de r√©aliser une pr√©vision √† court terme.

On emploie le lissage exponentiel simple (LES) lorsqu‚Äôil n‚Äôexiste aucune tendance.

Mais bien souvent il en existe une, et ce sont le lissage double (LED) et surtout le lissage de Holt qui viennent √† notre rescousse, voire le lissage de (Holt-Winters) s‚Äôil y a une saisonnalit√©.

### Lissage exponentiel simple(LES)

Si $\alpha$ est proche de 0, la pr√©vision est **rigide** et peu sensible aux fluctuations. En revanche, si $\alpha$ est proche de 1, la pr√©vision est **flexible** et tr√®s sensible aux variations.

L'expression de la pr√©vision est donn√©e par :

$$
S_t = \alpha \cdot y_t + (1 - \alpha) \cdot S_{t-1} + \epsilon
$$

ou encore :

$$
r(x) = \sum_{i=1}^{n} w \beta (x_i - x) Y_i
$$

Le param√®tre $\alpha$ permet de moduler l'importance des derni√®res r√©alisations par rapport √† l'ensemble de la s√©rie temporelle.

L'estimation de $\alpha$ se fait avec la formule suivante :

$$
\alpha = 1 - e^{-\frac{\Delta T}{\tau}}, \quad \alpha \in ]0, 1[
$$

```{r}

# Agr√©ger les flux par ann√©e (en prenant la somme des flux pour chaque ann√©e)
library(dplyr)
flux_per_year <- flux_per_day %>%
  group_by(annee) %>%
  summarise(flux_annuel = sum(flux))  # On suppose que 'flux' est la variable des flux journaliers

# Cr√©er la s√©rie temporelle annuelle
df_ts_annee <- ts(flux_per_year$flux_annuel, 
                  start = c(min(as.numeric(flux_per_year$annee))), 
                  frequency = 1)

# Afficher la s√©rie temporelle
#df_ts_annee
```

```{r}
#df_ts_annee <- df_ts_annee / 1e6
```

1.  Performance du mod√®le : ‚Ä¢ Le RMSE ( 693.44 ) et le MAE ( 590.13 ) indiquent une erreur importante dans les pr√©visions, ce qui peut √™tre d√ª √† des variations importantes ou des structures temporelles non mod√©lis√©es (par exemple, saisonnalit√© ou tendance). ‚Ä¢ La valeur √©lev√©e de MAPE ( 828.66 %) montre que les erreurs sont relativement grandes par rapport √† l‚Äô√©chelle des donn√©es.
2.  Impact de \alpha : ‚Ä¢ \alpha = 0.7198 refl√®te une pond√©ration plus forte pour les observations r√©centes, ce qui rend le mod√®le assez flexible pour s‚Äôadapter aux fluctuations r√©centes des donn√©es.
3.  R√©sidus : ‚Ä¢ L‚Äôautocorr√©lation n√©gative ( \text{ACF1} = -0.259 ) indique que les erreurs des pr√©visions successives sont partiellement corr√©l√©es, ce qui peut √™tre un signe que le mod√®le ne capture pas parfaitement la structure des donn√©es.

La formule de pr√©diction est :

$$
S_t = \alpha \sum_{j=0}^{T} (1 - \alpha)^j x_{T-j}
$$

Si nous observons $X_1, \dots, X_n$, nous avons :

-   **L'erreur moyenne (ME)** :\
    $$
    ME = \frac{1}{n} \sum_{t=1}^n e_t
    $$

-   **L'erreur quadratique moyenne (RMSE)** :\
    $$
    RMSE = \sqrt{\frac{1}{n} \sum_{t=1}^n e_t^2}
    $$

-   **L'erreur absolue moyenne (MAE)** :\
    $$
    MAE = \frac{1}{n} \sum_{t=1}^n |e_t|
    $$

-   **L'erreur en pourcentage moyenne (MPE)** :\
    $$
    MPE = 100 \times \frac{1}{n} \sum_{t=1}^n \frac{e_t}{X_t}
    $$

-   **L'erreur relative moyenne (MAPE)** :\
    $$
    MAPE = 100 \times \frac{1}{n} \sum_{t=1}^n \left| \frac{e_t}{X_t} \right|
    $$

-   **L'erreur moyenne normalis√©e** :\
    $$
    \frac{n-1}{n} \sum_{t=1}^n e_t \sum_{u=2}^n |X_u - X_{u-1}|
    $$

```{r}
class(df_ts_annee)  # Doit retourner "ts"
```

```{r}
# üìå Charger les biblioth√®ques n√©cessaires
library(ggplot2)
library(dplyr)
library(zoo)  # Pour interpolation des valeurs manquantes
library(forecast)  # Pour le lissage exponentiel simple (SES)

# ‚úÖ V√©rification et cr√©ation d'une copie de la s√©rie temporelle
df_ts_jour <- ts(df_ts_jour, start = start(df_ts_jour), frequency = frequency(df_ts_jour))

# ‚úÖ Appliquer le lissage exponentiel simple (SES) avec optimisation automatique d'alpha
fit_ets_ses <- ets(df_ts_jour, model = "ANN")  # "ANN" = Simple Exponential Smoothing (alpha optimis√©)

# ‚úÖ R√©sum√© du mod√®le avec les param√®tres optimis√©s
summary(fit_ets_ses)

# ‚úÖ R√©cup√©rer les valeurs liss√©es
df_results <- data.frame(
  index = time(df_ts_jour), 
  value = as.numeric(df_ts_jour),
  Pred_Exp = as.numeric(fitted(fit_ets_ses))  # Valeurs ajust√©es du mod√®le SES
)

# üìä üìå Graphique du mod√®le SES appliqu√© √† la s√©rie
ggplot(df_results, aes(x = index)) +
  geom_line(aes(y = value, color = "S√©rie Originale"), size = 1) +
  geom_line(aes(y = Pred_Exp, color = "Lissage Exponentiel"), size = 1.2) +
  labs(title = paste("Lissage Exponentiel Simple (SES) Appliqu√© √† la S√©rie"),
       x = "Index",
       y = "Valeur de la S√©rie") +
  scale_color_manual(values = c("S√©rie Originale" = "black", "Lissage Exponentiel" = "blue")) +
  theme_minimal()

# ‚úÖ Conserver df_ts_jour en tant que s√©rie temporelle
df_ts_jour <- ts(df_results$value, start = start(df_ts_jour), frequency = frequency(df_ts_jour))
pred_ts_exp <- ts(df_results$Pred_Exp, start = start(df_ts_jour), frequency = frequency(df_ts_jour))
```

Ce graphique montre une pr√©vision r√©alis√©e avec un mod√®le de lissage exponentiel ETS(A,N,N), adapt√© pour des s√©ries sans tendance ni saisonnalit√©. La courbe noire illustre les donn√©es historiques (2015-2020), marqu√©es par une forte variabilit√© autour de z√©ro. La courbe bleue repr√©sente les pr√©visions, qui montrent une stabilisation √† moyen terme. La zone grise correspond √† l'intervalle de confiance, qui s'√©largit progressivement, indiquant une incertitude croissante. Ce mod√®le convient si les donn√©es n‚Äôont pas de cycles ou de tendances significatifs.

### Lissage exponentiel double (LED)

On applique un second lissage exponentiel au premier lissage exponentiel simple afin de prendre en compte la tendance.

**Lissage exponentiel pour le niveau (**$L_t$) :

$$
   L_t = \alpha X_t + (1 - \alpha) [L_{t-1} + B_{t-1}]
   $$

o√π :

-   $L_t$ : Niveau liss√© √† l'instant $t$,

-   $X_t$ : Valeur observ√©e √† l'instant $t$,

-   $\alpha$ : Param√®tre de lissage pour le niveau (entre 0 et 1),

-   $L_{t-1}$ : Niveau liss√© √† l'instant $t-1$,

-   $B_{t-1}$ : Tendance estim√©e √† l'instant $t-1$.

**Lissage exponentiel pour la tendance (**$B_t$) :

$$
   B_t = \beta [L_t - L_{t-1}] + (1 - \beta) B_{t-1}
   $$ o√π :

-   $B_t$ : Tendance liss√©e √† l'instant $t$,

-   $\beta$ : Param√®tre de lissage pour la tendance (entre 0 et 1),

-   $L_t$ et $L_{t-1}$ : Niveau liss√© √† l'instant $t$ et $t-1$.

-   $\alpha$ et $\beta$ sont les param√®tres de lissage pour respectivement le niveau et la tendance.

-   Ces √©quations permettent de mod√©liser la tendance dans les s√©ries temporelles en combinant √† la fois un **lissage du niveau** et un **lissage de la tendance**.

```{r}
# üìå Charger les biblioth√®ques n√©cessaires
library(ggplot2)
library(dplyr)
library(zoo)  # Pour interpolation des valeurs manquantes
library(forecast)  # Pour le lissage exponentiel double (Holt)

# ‚úÖ Assurer que df_ts_jour est bien une s√©rie temporelle
df_ts_jour <- ts(df_ts_jour, start = start(df_ts_jour), frequency = frequency(df_ts_jour))

# ‚úÖ Appliquer le mod√®le de Holt avec estimation automatique des param√®tres
fit_holt <- holt(df_ts_jour, h = 10)  # "h = 10" est arbitraire, il est utilis√© uniquement pour la pr√©vision
summary(fit_holt)

# ‚úÖ R√©cup√©rer les valeurs ajust√©es (fitted values)
df_results <- data.frame(
  index = time(df_ts_jour), 
  value = as.numeric(df_ts_jour),
  Pred_Holt = as.numeric(fitted(fit_holt))  # Valeurs ajust√©es du mod√®le Holt
)

# üìä üìå Graphique du mod√®le Holt appliqu√© √† la s√©rie
ggplot(df_results, aes(x = index)) +
  geom_line(aes(y = value, color = "S√©rie Originale"), size = 1) +
  geom_line(aes(y = Pred_Holt, color = "Lissage Exponentiel Double"), size = 1.2) +
  labs(title = paste("Lissage Exponentiel Double (Holt) Appliqu√© √† la S√©rie"),
       x = "Index",
       y = "Valeur de la S√©rie") +
  scale_color_manual(values = c("S√©rie Originale" = "black", "Lissage Exponentiel Double" = "blue")) +
  theme_minimal()

# ‚úÖ Conserver df_ts_jour en tant que s√©rie temporelle
df_ts_jour <- ts(df_results$value, start = start(df_ts_jour), frequency = frequency(df_ts_jour))
pred_ts_holt <- ts(df_results$Pred_Holt, start = start(df_ts_jour), frequency = frequency(df_ts_jour))
```

1.  Performance du mod√®le : ‚Ä¢ Le RMSE ( 760.38 ) et le MAE ( 535.60 ) restent relativement √©lev√©s, refl√©tant des erreurs importantes dans les pr√©visions. ‚Ä¢ Le MAPE ( 245.06 %) indique une forte variabilit√© par rapport aux valeurs r√©elles, mais cela peut √™tre influenc√© par l‚Äô√©chelle de la s√©rie.
2.  Tendance estim√©e : ‚Ä¢ La tendance ( b = 959.52 ) sugg√®re une progression lin√©aire positive. Cela est refl√©t√© par la courbe bleue dans le graphique, qui montre une tendance √† long terme l√©g√®rement ascendante.
3.  R√©sidus : ‚Ä¢ L‚Äôautocorr√©lation r√©siduelle n√©gative ( \text{ACF1} = -0.487 ) indique que le mod√®le laisse des sch√©mas non captur√©s, sugg√©rant qu‚Äôil pourrait ne pas convenir parfaitement aux donn√©es.
4.  Pr√©cision des pr√©visions : ‚Ä¢ La zone gris√©e dans le graphique illustre une augmentation de l‚Äôincertitude au fur et √† mesure que l‚Äôon s‚Äô√©loigne des donn√©es historiques. Cela refl√®te une limite classique des m√©thodes de pr√©vision lin√©aire.

## Conclusion : M√©thodes de lissage

| Mod√®le | AIC | BIC | RMSE | MAE |
|---------------|---------------|---------------|---------------|---------------|
| **LOESS** | [**45499.93**]{style="color:green;"} | [**45542.99**]{style="color:green;"} | 42912681 | 21457482 |
| **Lissage exponentiel simple (LES)** | 54413.70 | 54429.20 | [**37517665**]{style="color:green;"} | [**15984248**]{style="color:green;"} |
| Lissage exponentiel double (LED) | 54417.83 | 54443.66 | 37519538 | 15983751 |

```         
‚Ä¢   LOESS est le meilleur mod√®le en termes de AIC et BIC, ce qui indique une meilleure qualit√© statistique du mod√®le.

‚Ä¢   Lissage exponentiel simple (LES) a les meilleures valeurs RMSE et MAE, ce qui signifie qu‚Äôil donne des pr√©visions plus pr√©cises en minimisant l‚Äôerreur.
```

# graphique

```{r}
# üìå Charger les biblioth√®ques n√©cessaires
library(ggplot2)
library(plotly)
library(dplyr)
library(forecast)  # Pour les mod√®les de lissage exponentiel
library(zoo)       # Pour la moyenne mobile
library(tsibble)   # Pour la manipulation des s√©ries temporelles

# ‚úÖ Cr√©ation d'une copie de la s√©rie temporelle originale avant modifications
df_ts_lissage <- df_ts_jour  

# ‚úÖ V√©rifier si `df_ts_jour` est une s√©rie temporelle et convertir en data.frame
if (is.ts(df_ts_jour)) {
  start_year <- start(df_ts_jour)[1]
  df_ts_jour_df <- data.frame(
    index = seq.Date(from = as.Date(paste0(start_year, "-01-01")), 
                     length.out = length(df_ts_jour), by = "day"),
    value = as.numeric(df_ts_jour)
  )
} else {
  df_ts_jour_df <- df_ts_jour
}

# ‚úÖ Conversion en tsibble pour analyse
df_ts_jour_df <- df_ts_jour_df %>%
  mutate(index = as.Date(index)) %>%
  as_tsibble(index = index)

# ‚úÖ Cr√©ation du DataFrame pour stocker les r√©sultats des mod√®les
df_results <- data.frame(Time = df_ts_jour_df$index, Observ√© = df_ts_jour_df$value)

# ‚úÖ Ajustement des mod√®les de lissage exponentiel

# 1Ô∏è‚É£ **Lissage Exponentiel Simple (LES)**
fit_les <- ets(df_ts_jour, model = "ANN")  # ETS avec tendance additive
df_results$Pred_LES <- fitted(fit_les)

# 2Ô∏è‚É£ **Lissage Exponentiel Double (Holt)**
fit_led <- ets(df_ts_jour, model = "AAN")  # Holt avec tendance
df_results$Pred_LED <- fitted(fit_led)

# 3Ô∏è‚É£ **Lissage LOESS (param√®tre span = 0.2)**
fit_loess <- loess(value ~ as.numeric(index), data = df_ts_jour_df, span = 0.2)
df_results$Pred_LOESS <- predict(fit_loess, newdata = df_ts_jour_df)

# 4Ô∏è‚É£ **Moyenne Mobile (fen√™tre de 7 jours)**
df_results$Pred_MA <- rollmean(df_results$Observ√©, k = 7, fill = NA, align = "right")

# üìä **Cr√©ation du graphique interactif avec ggplot2**
p <- ggplot(df_results, aes(x = as.Date(Time, origin = "1970-01-01"))) +  
  geom_line(aes(y = Observ√©, color = "S√©rie R√©elle"), size = 0.8) + 
  geom_line(aes(y = Pred_LES, color = "Lissage Exponentiel Simple (LES)"), size = 0.9) +
  geom_line(aes(y = Pred_LED, color = "Lissage Exponentiel Double (LED)"), size = 0.9) +
  geom_line(aes(y = Pred_LOESS, color = "Lissage LOESS"), size = 0.9) +
  geom_line(aes(y = Pred_MA, color = "Moyenne Mobile (7 jours)"), size = 0.9) +

  # ‚úÖ Mise en forme des axes
  scale_x_date(date_breaks = "1 year", date_labels = "%Y") +
  scale_y_continuous(labels = scales::comma) +

  # ‚úÖ Attribution des couleurs aux mod√®les
  scale_color_manual(values = c(
    "S√©rie R√©elle" = "black",
    "Lissage Exponentiel Simple (LES)" = "blue",
    "Lissage Exponentiel Double (LED)" = "red",
    "Lissage LOESS" = "goldenrod",
    "Moyenne Mobile (7 jours)" = "green"
  )) +

  # ‚úÖ Ajout de titres et l√©gendes
  labs(title = "Comparaison des Mod√®les de Lissage",
       x = "Ann√©e",
       y = "Valeur de la S√©rie",
       color = "Mod√®les") +

  # ‚úÖ Style graphique
  theme_minimal() +
  theme(plot.title = element_text(face = "bold", hjust = 0.5, size = 14),
        axis.title = element_text(face = "bold"),
        legend.position = "right")

# üìå Transformer en graphique interactif avec `plotly`
ggplotly(p) %>%
  layout(legend = list(orientation = "v", x = 1, y = 0.5))

# ‚úÖ **Reconstruire `df_ts_jour` comme s√©rie temporelle apr√®s analyse**
df_ts_jour <- ts(df_ts_jour_df$value, start = start(df_ts_lissage), frequency = frequency(df_ts_lissage))

```

# Meilleur mod√®le parmis les deux m√©thodes : regression et lissage

| Mod√®le | AIC | BIC | RMSE | MAE |
|---------------|---------------|---------------|---------------|---------------|
| **GAM** | 49172.66 | 49218.41 | 42903873 | 21341575 |
| **LOESS** | [**45499.93**]{style="color:green;"} | [**45542.99**]{style="color:green;"} | 42912681 | 21457482 |
| **Lissage exponentiel simple (LES)** | 54413.70 | 54429.20 | [**37517665**]{style="color:green;"} | [**15984248**]{style="color:green;"} |

üìä Analyse des r√©sultats :

1.AIC et BIC :

‚Ä¢ LOESS est le meilleur mod√®le avec le plus faible AIC (45499.93) et BIC (45542.99).

‚Ä¢ GAM arrive en second (AIC = 49172.66, BIC = 49218.41).

‚Ä¢ Le lissage exponentiel simple (LES) est le pire en AIC/BIC. 

2. Erreur de pr√©diction (RMSE & MAE) :

‚Ä¢ Le mod√®le LES a les erreurs les plus faibles (RMSE = 37517665, MAE = 15984248), ce qui indique qu‚Äôil est le plus pr√©cis en pr√©diction.

‚Ä¢ GAM et LOESS ont des erreurs similaires en RMSE et MAE.

| üéØ Crit√®re | üèÜ Meilleur Mod√®le |
|--------------------------------------|----------------------------------|
| **Mod√®le avec le plus faible AIC & BIC** | **LOESS** |
| **Mod√®le avec les plus faibles erreurs (RMSE & MAE)** | **Lissage exponentiel simple (LES)** |
| **Meilleur compromis global** | **LOESS** |

# Analyse des r√©sidus du mod√®le de moyenne mobile

üí° Objectif : V√©rifier si le mod√®le Lissage exponentiel simple (LES) est bien ajust√© √† notre s√©rie temporelle en analysant ses r√©sidus.

## Visualiser les R√©sidus

```{r}
library(ggplot2)
library(forecast)
library(tseries)

# ‚úÖ Appliquer le mod√®le de lissage exponentiel simple (ETS "ANN")
fit_ets_ses <- ets(df_ts_jour, model = "ANN")

# ‚úÖ Extraction des r√©sidus
residuals_les <- residuals(fit_ets_ses)

ggplot(data.frame(Time = time(residuals_les), Residus = residuals_les), aes(x = Time, y = Residus)) +
  geom_line(color = "blue") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(title = "√âvolution des R√©sidus du Lissage Exponentiel Simple (ETS 'ANN')", 
       x = "Temps", y = "R√©sidus") +
  theme_minimal()
```

Les r√©sidus semblent osciller autour de z√©ro, mais des pics importants sont visibles, ce qui peut indiquer une mauvaise capture des variations par le mod√®le.

```{r}
ggplot(data.frame(Residus = residuals_les), aes(x = Residus)) +
  geom_histogram(color = "black", fill = "blue", bins = 30, alpha = 0.7) +
  geom_vline(xintercept = mean(residuals_les, na.rm = TRUE), linetype = "dashed", color = "red") +
  labs(title = "Distribution des R√©sidus du LES (ETS 'ANN')", 
       x = "R√©sidus", y = "Fr√©quence") +
  theme_minimal()
```

Forte concentration des r√©sidus autour de z√©ro, ce qui peut sugg√©rer un biais dans l‚Äôajustement du mod√®le.

## QQ-plot pour v√©rifier la normalit√©

```{r}
qqnorm(residuals_les, main = "QQ-plot des R√©sidus du LES (ETS 'ANN')")
qqline(residuals_les, col = "red")
```

Les r√©sidus ne suivent pas une distribution normale, ce qui est confirm√© par le test de Shapiro-Wilk.

## Autocorr√©logramme des r√©sidus (ACF)

```{r}
acf(residuals_les, main = "Autocorr√©logramme des R√©sidus du LES (ETS 'ANN')")
```

Aucune autocorr√©lation significative observ√©e, validant ainsi l‚Äôhypoth√®se que les erreurs sont ind√©pendantes.

## Tests Statistiques sur les R√©sidus

### Test de normalit√© de Shapiro-Wilk

```{r}
shapiro.test(residuals_les)
```

```         
‚Ä¢   üìå p-value < 0.05 : On rejette l‚Äôhypoth√®se nulle de normalit√©.

‚Ä¢   Conclusion : Les r√©sidus ne suivent pas une distribution normale. Cela sugg√®re que le mod√®le pourrait √™tre am√©lior√©, car un bon mod√®le produit g√©n√©ralement des r√©sidus normalement distribu√©s.
```

### Test de Ljung-Box pour v√©rifier l‚Äôautocorr√©lation

```{r}
Box.test(residuals_les, type = "Ljung-Box")
```

üìå p-value \> 0.05 : On ne rejette pas l‚Äôhypoth√®se nulle d‚Äôabsence d‚Äôautocorr√©lation.

```         
‚Ä¢   Conclusion : Les r√©sidus ne pr√©sentent pas d‚Äôautocorr√©lation significative, ce qui est un bon signe pour la validit√© du mod√®le.
```

### Test de stationnarit√© de Dickey-Fuller Augment√© (ADF)

```{r}
adf.test(residuals_les)
```

```         
‚Ä¢   üìå p-value < 0.05 : On rejette l‚Äôhypoth√®se nulle de non-stationnarit√©.

‚Ä¢   Conclusion : Les r√©sidus sont stationnaires, ce qui signifie que le mod√®le ne pr√©sente pas de tendance non expliqu√©e.
```

üéØ Bilan Global

| Crit√®re | R√©sultat | Interpr√©tation |
|-----------------------|------------------------------|-------------------|
| **Normalit√© (Shapiro-Wilk)** | ‚ùå Non normale (p \< 0.05) | Mod√®le √† am√©liorer |
| **Autocorr√©lation (Ljung-Box)** | ‚úÖ Pas d‚Äôautocorr√©lation (p \> 0.05) | Mod√®le valide |
| **Stationnarit√© (ADF Test)** | ‚úÖ Stationnaire (p \< 0.05) | Mod√®le valide |

# Mod√®le ARIMA, diff√©renciation et stationarit√©.

**D√©finition d'un processus ARMA**

Un processus $(Y_t)$ est un processus **ARMA d‚Äôordre** $p$ et $q$, not√© **ARMA(p, q)**, si :

$$
Y_t - \sum_{i=1}^p \phi_i Y_{t-i} = \epsilon_t - \sum_{i=1}^q \theta_i \epsilon_{t-i}
$$

**Param√®tres**

-   $p$ : l'ordre de la composante autor√©gressive (**AR**, Autoregressive).
-   $q$ : l'ordre de la composante moyenne mobile (**MA**, Moving Average).
-   $Y_t$ : la valeur de la s√©rie au temps $t$.
-   $\phi_i$ : les coefficients de la partie autor√©gressive.
-   $\epsilon_t$ : un bruit blanc centr√© ($\mathbb{E}[\epsilon_t] = 0$, $\text{Var}[\epsilon_t] = \sigma^2$).
-   $\theta_i$ : les coefficients de la partie moyenne mobile.

**orme compacte**

Le mod√®le ARMA(p, q) combine :

1.  **AR(p)** : $Y_t = \sum_{i=1}^p \phi_i Y_{t-i} + \epsilon_t$

2.  **MA(q)** : $Y_t = \epsilon_t - \sum_{i=1}^q \theta_i \epsilon_{t-i}$

Ensemble, cela donne l'√©quation g√©n√©rale ci-dessus.

------------------------------------------------------------------------

```{r}
ggAcf(df_ts_jour,lag=200)
```

```{r}
ggAcf(df_ts_jour,lag=100)
```

```{r}
ggAcf(df_ts_jour,lag=50)
```

```{r}
ggPacf(df_ts_jour,lag=200)
```

## Diff√©rentiation et stationarit√©.

La diff√©renciation est une technique utilis√©e en analyse des s√©ries temporelles pour rendre une s√©rie stationnaire en √©liminant les tendances ou les variations cycliques. Elle consiste √† calculer la diff√©rence entre une observation et sa valeur pr√©c√©dente, cr√©ant ainsi une nouvelle s√©rie. Par exemple, pour une s√©rie $Y_t$, la diff√©renciation produit une nouvelle s√©rie $Z_t = Y_t - Y_{t-1}$. Cette m√©thode est couramment utilis√©e dans les mod√®les ARIMA pour r√©pondre √† la condition de stationnarit√©. Cependant, une diff√©renciation excessive peut entra√Æner la perte d'informations importantes sur la structure de la s√©rie.

### Fonction ndiffs

La fonction **ndiffs** permet de d√©terminer le nombre de diff√©renciations n√©cessaires pour rendre une s√©rie temporelle stationnaire en faisant les diff√©rents test de saisonalit√©, *kpss*, *adf*, *pp*.

#### Test du nombre de diff√©renciation

```{r}
ndiffs(df_ts_lissage,test =c("kpss", "adf", "pp")) 
```

```{r}
diff_ts = diff(df_ts_lissage)
```



## ARIMA

### Application Modele de base

#### ACF et PACF

```{r}
ggAcf(diff_ts, lag = 80)
ggPacf(diff_ts , lag = 80)
```

Cela sug√®re que q = 1 et p = 5

#### Mod√©lisation de ARIMA et Auto ARIMA

```{r}
model_arima <- auto.arima((diff_ts))
summary(model_arima)

```

Notre mod√®le *ARIMA(0,0,0)* indique que les donn√©es ne pr√©sentent aucune structure temporelle exploitable, ce qui correspond √† un bruit blanc.
Auto-ARIMA l‚Äôa s√©lectionn√© car il pr√©sente un AIC plus faible que les autres mod√®les test√©s.
Dans notre cas, un ARIMA(0,1,0) serait plus appropri√©, indiquant une marche al√©atoire.
Cela est coh√©rent avec le mod√®le de *lissage exponentiel simple*, o√π les r√©sidus ne montrent pas d'autocorr√©lation significative.

### R√©sidus du mod√®le

```{r}
acf(residuals(model_arima))
pacf(residuals(model_arima))

### Mod√®le Box-Cox ARIMA
```
On a regard√© les r√©sidus mais cela n'est pas vraiment utile au vu de nos r√©sultats pr√©c√©dents.




